<!DOCTYPE html>
<html>
<head>
    <base target="_top">
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            height: 100vh;
            width: 100vw;
            display: flex;
            justify-content: center;
            align-items: center;
            box-sizing: border-box;
            position: relative;
            overflow: hidden;
            background-color: black;
        }

        .animated-border::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 100%;
            height: 20px;
            background: linear-gradient(90deg, rgba(255, 182, 193, 0.7), rgba(255, 223, 186, 0.7), rgba(255, 255, 186, 0.7), rgba(186, 255, 201, 0.7), rgba(186, 255, 255, 0.7), rgba(201, 186, 255, 0.7), rgba(255, 186, 255, 0.7));
            filter: blur(10px);
            background-size: 200% 200%;
            box-shadow: 0 0 10px rgba(255, 182, 193, 0.7),
                        0 0 20px rgba(255, 223, 186, 0.7),
                        0 0 30px rgba(255, 255, 186, 0.7),
                        0 0 40px rgba(186, 255, 201, 0.7),
                        0 0 50px rgba(186, 255, 255, 0.7),
                        0 0 60px rgba(201, 186, 255, 0.7),
                        0 0 70px rgba(255, 186, 255, 0.7);
            transition: transform 0.5s cubic-bezier(0.4, 0, 0.2, 1), opacity 0.5s ease;
            pointer-events: none;
            transform: scaleX(0);
        }

        .animated-border.active::after {
            transform: scaleX(1);
        }

        .animated-border.out::after {
            transform: scaleX(0);
            opacity: 0;
        }

        @keyframes gradientBorder {
            0% {
                background-position: 0% 50%;
            }
            50% {
                background-position: 100% 50%;
            }
            100% {
                background-position: 0% 50%;
            }
        }

        .animated-border::after {
            animation: gradientBorder 5s ease infinite;
        }

        .wave::after {
            animation: gradientBorder 5s ease infinite, wave 1s infinite;
        }

        @keyframes wave {
            0%, 100% {
                transform: scaleY(1);
            }
            25% {
                transform: scaleY(calc(1 + (Math.random() * 0.2 - 0.1)));
            }
            50% {
                transform: scaleY(calc(1 + (Math.random() * 0.4 - 0.2)));
            }
            75% {
                transform: scaleY(calc(1 + (Math.random() * 0.2 - 0.1)));
            }
        }

        #status {
            z-index: 1;
            color: white;
        }
    </style>
</head>
<body>
    <p id="status">聞き取り中...</p>
    <audio id="wakeSound" src="https://x.gd/pug6h"></audio>
    <audio id="cancelSound" src="https://x.gd/Jz4Ej"></audio>
    <script>
        window.onload = function() {
            const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.lang = 'ja-JP';
            recognition.continuous = true;
            recognition.interimResults = false;

            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            let source = null;

            let isMonitoring = false;
            let timeoutId = null;
            let idleTimeoutId = null;

            const startMonitoring = async () => {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                source = audioContext.createMediaStreamSource(stream);
                source.connect(analyser);
                isMonitoring = true;
                monitorVolume();
            };

            const stopMonitoring = () => {
                isMonitoring = false;
                if (source) {
                    source.disconnect();
                    source = null;
                }
            };

            const monitorVolume = () => {
                if (!isMonitoring) return;
                analyser.getByteFrequencyData(dataArray);
                const volume = dataArray.reduce((a, b) => a + b) / dataArray.length;
                if (volume < 10) {
                    if (!idleTimeoutId) {
                        idleTimeoutId = setTimeout(() => {
                            document.body.classList.remove('active');
                            document.body.classList.add('out');
                            document.body.classList.remove('wave');
                            document.getElementById('cancelSound').play();
                            document.getElementById('status').innerText = '聞き取り中...';
                            stopMonitoring();
                        }, 5000);
                    }
                } else {
                    clearTimeout(idleTimeoutId);
                    idleTimeoutId = null;
                    if (!document.body.classList.contains('wave')) {
                        document.body.classList.add('wave');
                    }
                }
                requestAnimationFrame(monitorVolume);
            };

            recognition.onresult = (event) => {
                const transcript = event.results[event.results.length - 1][0].transcript.trim();
                console.log('Recognized:', transcript);

                if (transcript.includes('にゃん')) {
                    console.log('にゃんだよ！どうしたの？');
                    document.getElementById('status').innerText = 'にゃんだよ！どうしたの？';
                    document.body.classList.add('animated-border', 'active');
                    document.body.classList.remove('out');
                    document.getElementById('wakeSound').play();
                    clearTimeout(timeoutId);
                    clearTimeout(idleTimeoutId);
                    startMonitoring();
                }
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
            };

            recognition.onend = () => {
                recognition.start();
            };

            recognition.start();
        };
    </script>
</body>
</html>
